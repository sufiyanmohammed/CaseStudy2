---
title: "CaseStudy2"
output: html_document
author: Sufiyan Mohammed
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#adding a lot of libraries but probably won't use all 
ibrary(tidyverse)
library(GGally)
library(naniar)
library(dplyr)
library(class)
library(caret)
library(e1071)
library(ggplot2)
library(plotly)
library(corrplot)
library(class)
library(Metrics)
setwd("/Users/sufi/Documents/MSDS_6306_Doing-Data-Science-Master/Unit 14 and 15 Case Study 2")


#Import
data = read.csv("CaseStudy2-data.csv", header = TRUE)
head(data)

#removing useless variables
data2 = data %>% select(-c('ID', 'EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours'))
data2


#calculating rate of attrition
rateofattrition <- sum(data2$Attrition == "Yes")/nrow(data2)
rateofattrition
#Average rate of 16%


#EDA
newglm <- glm(data2$Attrition ~ ., family = binomial(link="logit"), data = data2)
newglm


#creating correlations to understand data
datanumeric <- data2[, sapply(data2,is.integer)]
correlations <- cor(datanumeric)
corrplot(correlations, method="circle")


#dividing data into factors
datafactor <- data2 %>%
  mutate_if(sapply(data2, is.character), as.factor)


#dividing data into integers
datainteger <- datafactor %>%
  mutate_if(sapply(datafactor, is.factor), as.integer)


#numeric correlations
datainteger.cor= cor(datainteger)
corrplot(datainteger.cor)

### histograms for viewing datasets for further evaluation
hist(datafactor$MonthlyIncome)

hist(datafactor$DistanceFromHome)

hist(datafactor$JobSatisfaction)

### plots to understand relationships between attrition and other variables 
plot(datafactor$Attrition,datafactor$MonthlyIncome)

plot(datafactor$Attrition,datafactor$DistanceFromHome)

plot(datafactor$Attrition,datafactor$JobRole)



plot(datafactor$Attrition,datafactor$OverTime, main="Overtime vs Attrition", xlab="Overtime",ylab="Attrition")

plot(datafactor$Attrition,datafactor$DistanceFromHome, main="Distance from Home vs Attrition", xlab="Attrition",ylab="Distance From Home")

plot(datafactor$Attrition,datafactor$Age, main="Age vs Attrition", xlab="Attrition",ylab="Age")

plot(datafactor$Attrition,datafactor$Age)


#########going to use these plots in the presentation: might change to ggplot to make it better looking later 
plot(datafactor$MonthlyIncome,datafactor$JobLevel, main="Monthly Income vs Job Level", xlab="Monthly Income", ylab="Job Level")
plot(datafactor$MonthlyIncome,datafactor$TotalWorkingYears, main="Monthly Income vs Total Working Years", xlab="Monthly Income", ylab="Total Working Years")
plot(datafactor$MonthlyIncome,datafactor$BusinessTravel, main="Monthly Income vs Business Travel", xlab="Monthly Income", ylab="Business Travel")



#creating train/test
datapartition = createDataPartition(data$Attrition, times = 1, p = 0.7, list = FALSE)
train = data[datapartition,]
test = data[-datapartition,]


#testing NB
NBclassifier=naiveBayes(Attrition~., data=train)
print(NBclassifier)
NBclassifier

pred<- predict(NBclassifier, test)


#Testing cfm
cfm <-confusionMatrix((table(pred, test$Attrition)))
ggplotConfusionMatrix(cfm)


###
### NaiveBayes Model! Seeded to determine best seed, takes over a minute to run!

theaccuracy <-  numeric(100)
thesensitivity  <-  numeric(100)
thespecificity <-  numeric(100)
theseed <-  numeric(1000)
for(seed in 1:1000)
{
  set.seed(seed)
  split = 0.75
  
  model = sample(1:dim(data2)[1],round(split * dim(data2)[1]))
  train = data2[model,]
  test = data2[-model,]
  
  model2 = naiveBayes(train[,c("OverTime", "DistanceFromHome", "Age")], factor(train$Attrition, labels=c("No", "Yes")))
  cfm = confusionMatrix(table(factor(test$Attrition, labels = c("No", "Yes")), predict(model2,test[,c("OverTime", "DistanceFromHome", "Age")])))
  
  theaccuracy[seed] <-  cfm$overall[1]
  thesensitivity[seed]  <-  cfm$byClass[1]
  thespecificity[seed]  <-  cfm$byClass[2]
  theseed[seed] <-  seed
}
mean(theaccuracy)
mean(thesensitivity)
mean(thespecificity)
mean(theseed)
theseed

####


### seed 4 is chosen for the actual model below 
set.seed(4)
split = 0.75

model = sample(1:dim(data2)[1],round(split * dim(data2)[1]))
train = data2[model,]
test = data2[-model,]

model2 = naiveBayes(train[,c("OverTime", "DistanceFromHome", "Age")], factor(train$Attrition, labels=c("No", "Yes")))
cfm = confusionMatrix(table(factor(test$Attrition, labels = c("No", "Yes")), predict(model2,test[,c("OverTime", "DistanceFromHome", "Age")])))
cfm
plot(cfm)

###Inputing data onto attrition csv

attritioncsv=read.csv("CaseStudy2CompSet No Attrition.csv", header = TRUE)

attritioncsv$newattrition<-predict(model2,attritioncsv[,c("OverTime", "DistanceFromHome", "Age")])

write_csv(attritioncsv[,c(1,36)], "Case2PredictionsMohammed Attrition.csv")


#EDA on a seperate R file, determined job level, working hours, and business travel to be good variables. 
#overall monthly income
hist(data2$MonthlyIncome)


#general linear model
linearmodel= lm(MonthlyIncome~JobLevel+TotalWorkingYears+BusinessTravel, data=train)
summary(linearmodel)

hist(linearmodel$residuals, col = "red", main = "Residual Histogram", xlab="Residuals")
plot(linearmodel$fitted.values,linearmodel$residuals, main = "Residuals vs Fitted Values", xlab="Fitted Values", ylab="Residuals")
abline(a=0, b=0)


#predictive model 
linearmodelprediction<- predict(linearmodel, newdata=test)

plot(linearmodelprediction,test$MonthlyIncome, main="Model Prediction vs Actual Monthly Income", xlab="Model Prediction", ylab="Monthly Income")
abline(a=0,b=1)


###RMSE of 1306
rmse(test$MonthlyIncome,linearmodelprediction)

summary(linearmodelprediction)

####creating other CSV file

monthlyincomecsv=read.csv("CaseStudy2CompSet No Salary.csv", header=TRUE)

monthlyincomecsv$predictedsalary<-predict(linearmodel,monthlyincomecsv[,c("JobLevel","TotalWorkingYears","BusinessTravel")])

write_csv(monthlyincomecsv[,c(1,36)], "Case2PredictionsMohammed MonthlySalary.csv")


